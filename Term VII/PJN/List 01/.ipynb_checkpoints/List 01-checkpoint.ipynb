{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10% of the file contents...\n",
      "Processed 20% of the file contents...\n",
      "Processed 30% of the file contents...\n",
      "Processed 40% of the file contents...\n",
      "Processed 50% of the file contents...\n",
      "Processed 60% of the file contents...\n",
      "Processed 70% of the file contents...\n",
      "Processed 80% of the file contents...\n",
      "Processed 90% of the file contents...\n",
      "Processed 100% of the file contents...\n"
     ]
    }
   ],
   "source": [
    "from gatherer import gather_words_from_file\n",
    "\n",
    "words = gather_words_from_file(filename='polish_corpora.txt', lines_to_read=500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(tokenization_attempt, proper_tokenization):\n",
    "    score = 0\n",
    "    for token in tokenization_attempt:\n",
    "        if token in proper_tokenization:\n",
    "            score +=1\n",
    "    return score / len(proper_tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(['t1', 't2t3', 't3'], ['t1', 't2', 't3', 't3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_match(text):\n",
    "    tokens = []\n",
    "    current_token = ''\n",
    "    for letter in text:\n",
    "        extended_token = current_token + letter\n",
    "        if extended_token in words:\n",
    "            current_token = extended_token\n",
    "        else:\n",
    "            tokens.append(current_token)\n",
    "            current_token = letter\n",
    "    if current_token != '':\n",
    "        tokens.append(current_token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_compare(line):\n",
    "    proper_tokenization = line.lower().split(' ')\n",
    "    processed_line = \"\".join(line.split()).lower()\n",
    "    attempted_tokenization = max_match(processed_line)\n",
    "    score = get_score(attempted_tokenization, proper_tokenization)\n",
    "    print(f'expected: {proper_tokenization}')\n",
    "    print(f'got: {attempted_tokenization}')\n",
    "    print(f'score: {score}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected: ['system', 'euroraty', 'chcesz', 'kupować', 'więcej', 'niż', 'gdzie', 'indziej', '?']\n",
      "got: ['syst', 'eme', 'uro', 'raty', 'ch', 'ces', 'zk', 'upo', 'wać', 'więc', 'ej', 'niż', 'gd', 'zie', 'ind', 'zie', 'j', '?']\n",
      "score: 0.2222222222222222\n",
      "\n",
      "expected: ['parlament', 'zdecydował', 'jednak', 'inaczej', 'i', 'przyjął', 'w', 'ustawie', 'z', 'dnia', '28.06.1996', 'r.', 'jednoinstancyjne', 'postępowanie', 'orzeczniczo-lekarskie', '.']\n",
      "got: ['par', 'lam', 'en', 'tz', 'dec', 'y', 'dowa', 'ł', 'jednak', 'ina', 'czej', 'ip', 'rzy', 'jął', 'wu', 'stawie', 'zd', 'nia', '28.', '06.', '1996r', '.', 'jedno', 'insta', 'nc', 'yj', 'nep', 'ost', 'ę', 'pow', 'anie', 'orz', 'ec', 'zn', 'ic', 'zo', '-', 'lek', 'ars', 'kie', '.']\n",
      "score: 0.1875\n",
      "\n",
      "expected: ['po', 'kampanii', 'wrześniowej', '1.dlek', 'raportowała', '77', 'czołgów', 'l.t.m.35', 'utraconych', '(', 'wraz', 'z', 'wozami', 'dowodzenia', ')', 'i', '52', 'uszkodzone', 'lub', 'zepsute', ',', 'lecz', 'ostatecznie', 'po', 'naprawach', 'straty', 'bezpowrotne', 'ograniczyły', 'się', 'do', '7', 'czołgów', 'i', 'w', 'lutym', '1940', 'roku', 'posiadano', '195', 'czołgów', 'na', 'stanie', '.']\n",
      "got: ['poka', 'mpa', 'nii', 'wrze', 'ś', 'nio', 'wej', '1.', 'dle', 'krap', 'orto', 'wała', '77', 'czo', 'ł', 'gó', 'wl', '.', 't.', 'm.', '35', 'ut', 'rac', 'on', 'ych', '(', 'wraz', 'zwo', 'zam', 'ido', 'wodze', 'nia', ')', 'i5', '2', 'usz', 'kod', 'zo', 'nel', 'ub', 'zep', 'su', 'te', ',', 'lecz', 'ost', 'ate', 'cz', 'nie', 'pona', 'prawa', 'ch', 'straty', 'bez', 'pow', 'rot', 'neo', 'granic', 'zy', 'ły', 'się', 'do', '7c', 'zo', 'ł', 'gó', 'wiw', 'lutym', '1940r', 'okup', 'osi', 'ada', 'no', '195', 'czo', 'ł', 'gó', 'wn', 'asta', 'nie', '.']\n",
      "score: 0.3023255813953488\n",
      "\n",
      "expected: ['w', 'rolach', 'głównych', 'wystąpili', 'jake', 'gyllenhaal', ',', 'forest', 'whitaker', 'oraz', 'rachel', 'mcadams', '.']\n",
      "got: ['wrol', 'ach', 'głów', 'nych', 'wyst', 'ą', 'pili', 'jake', 'gy', 'll', 'en', 'ha', 'al', ',', 'fore', 'stw', 'hita', 'ker', 'oraz', 'rach', 'elm', 'cada', 'ms', '.']\n",
      "score: 0.3076923076923077\n",
      "\n",
      "expected: ['zapieczone', 'z', 'pomidorami', ',', 'bazylią', 'i', 'serem', '...']\n",
      "got: ['zap', 'iec', 'zo', 'nez', 'pomi', 'dora', 'mi', ',', 'bazylią', 'ise', 'rem', '...']\n",
      "score: 0.375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('polish_corpora.txt', encoding='utf8') as f:\n",
    "    for _ in range(5):\n",
    "        line = next(f).rstrip('\\n')\n",
    "        tokenize_and_compare(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The file is kind of scuffed ngl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nie ch ju ż naw et nie będ zie str a żn ic zk ą , a le n ie ch w o góle b ęd zie .\n",
      "Moze nie trzeba by bylo interweniowac a miejsce w zk przydaloby sie komus innemu .\n",
      "A to , czy jakis pies kryl warunkowo czy nie , czy zk jest fajny czy be ...\n"
     ]
    }
   ],
   "source": [
    "with open('polish_corpora.txt', encoding='utf-8') as f:\n",
    "        for _ in range(500000):\n",
    "            line = next(f).rstrip('\\n')\n",
    "            words_in_line = line.split(' ')\n",
    "            if 'zk' in words_in_line:\n",
    "                print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10% of the file contents...\n",
      "Processed 20% of the file contents...\n",
      "Processed 30% of the file contents...\n",
      "Processed 40% of the file contents...\n",
      "Processed 50% of the file contents...\n",
      "Processed 60% of the file contents...\n",
      "Processed 70% of the file contents...\n",
      "Processed 80% of the file contents...\n",
      "Processed 90% of the file contents...\n",
      "Processed 100% of the file contents...\n"
     ]
    }
   ],
   "source": [
    "from gatherer import gather_successors_from_bigrams\n",
    "\n",
    "successors2 = gather_successors_from_bigrams('poleval_2grams.txt', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bcs , okwiat ma iść środki ministra dariusza wójcika - podejmować uchwały absolutoryjnej , 14-16 podoficerów służby tej krzywej ) nakazują w brytyjski parlament uchwalał ustawy popiwkowej , pasujących . leopolda stokowskiego . us valenciennes , wyszukane , aksamitna . 45 st. thomas alsgaard\n",
      "tożsamość osoby słabiej ( okazy przyrodnicze , starszy referent wydziału podstawowych praw . 110 milionów ofiar ? <EOS>\n",
      "simc ( szkolne koła miały sporo namieszać , rozumnym , bordowe\n",
      "gioiosa marca 2008r , andersa do miastka , el w sukiennicach , spoczywa więc naturalnym zagłębieniu się koalicja rządząca chce również wysłuchamy 5-minutowych oświadczeń co stworzyło bardzo istotny wskaźnik , nhl entry was przy ponownym zjednoczeniu się willa została kampania ma zadłużenie w 832 . lech nadarkiewicz\n",
      "zijinshan w śpiew tadeusz borowski mówił wprost lub zawód . iwona i mieszkaniowym nie wykryło\n"
     ]
    }
   ],
   "source": [
    "from sentence import BigramSG\n",
    "\n",
    "bisg = BigramSG(successors2)\n",
    "print(bisg.generate_text(sentences=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10% of the file contents...\n",
      "Processed 20% of the file contents...\n",
      "Processed 30% of the file contents...\n",
      "Processed 40% of the file contents...\n",
      "Processed 50% of the file contents...\n",
      "Processed 60% of the file contents...\n",
      "Processed 70% of the file contents...\n",
      "Processed 80% of the file contents...\n",
      "Processed 90% of the file contents...\n",
      "Processed 100% of the file contents...\n"
     ]
    }
   ],
   "source": [
    "from gatherer import gather_successors_from_trigrams\n",
    "\n",
    "successors3 = gather_successors_from_trigrams('poleval_3grams.txt', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jego kandydatury na stanowisko prezydenta , o najniższych kwalifikacjach . <EOS>\n",
      "tomach w latach bezpośrednio poprzedzających jego podbój przez turków . <EOS>\n",
      "janusz korczak ,\n",
      "wp , 1998 ( grupa 2\n",
      "ławników do orzekania przez sąd apelacyjny -\n",
      "akcją popisał się w konstytucji prl z dnia 10 stycznia . <EOS>\n",
      "tytułu prowadzenia pozarolniczej działalności w organizacji spotkań z rolnikami . <EOS>\n",
      "wyprawę , której liczba\n",
      "nasze błędy , że cywilizacja\n",
      "równouprawnienia i przeciwdziałania negatywnym skutkom wykonywania pracy za ich wprowadzenie nie\n"
     ]
    }
   ],
   "source": [
    "from sentence import TrigramSG\n",
    "\n",
    "trisg = TrigramSG(successors3)\n",
    "print(trisg.generate_text(sentences=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_successors3 = {\n",
    "    ('alfa', 'beta'): [(1, 'charlie')],\n",
    "    ('beta', 'charlie'): [(1, 'delta')],\n",
    "    ('charlie', 'delta'): [(1, 'echo')],\n",
    "    ('delta', 'echo'): [(1, '<EOS>'), (1, 'foxtrot')]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alfa beta charlie delta echo <EOS>\n",
      "delta echo foxtrot\n",
      "charlie delta echo foxtrot\n",
      "delta echo foxtrot\n",
      "charlie delta echo foxtrot\n"
     ]
    }
   ],
   "source": [
    "trisg = TrigramSG(dummy_successors3)\n",
    "sentence = trisg.generate_text(sentences=5)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence import NonUniformSentenceGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finchera , lyrics ) pomógł . 3.14 ) podpisane prawdopodobnie najstarsze inskrypcje : aha jeszcze długie a due , ustawodawczą - skład krajowych stowarzyszeń fotograficznych w polskojęzycznej wersji komercyjnej w pęcherzyku żółciowym . : diablo 2 cztery sektory polskiej podpisał konstytucję lub finansowanych , odrazu po wstrzyknięciu\n",
      "szeged ( song ) zlokalizowany wtedy zgodnie - zwiększać swoje miejsca jest złożeniem przez potencjał polskiego ds. rybołówstwa nie negował , teleinformatycznych oraz chorzy pacjenci nabywają wiadomości komisji uwzględnione na warsztacie i giuseppe verdiego w dwa okrążenia przed resztą załogi międzynarodowej współpracy władz celnych przywozowych i uzyskiwane od zwiedzania okolicy ich pojęciu jest zagospodarowana z gnoju , zakazaną przez radiostacje i ppoż . 23 500 policjantów został zestrzelony podczas potopu w przewlekłej i miejcie na przemarsz , sceneria i wypracowany wspólnie zastanowimy , lada problemem naszego powszedniego , oscylując\n",
      "pułapka w peruwiańskiej primera p12\n",
      "okrywie włosowej . okres wymagany termin medyczny : hali ) promującymi płytę artystki ) powróciła także zaprezentowanie na trasach ) międzynarodowych mistrzostw albanii , 215 euro odszkodowania przysługującego z dzisiejszych możliwościach korzystania poza podziałem pracy swoistych sankcji onz do bokserskiej . ! <EOS>\n",
      "mind over 100 gatunków m.in. kolejne obciążenia tego entuzjazmu w 1481 i wiedeńskiej poświęcona świętemu mikołajowi ii plus że zakres instrumentów o sprawowanie przewodnictwa elektrycznego ) określających m.in. ujednolicenie stawek ryczałtu jest andrew lloyda wrighta , migotaniach , drobiowego i właścicielom - zwykli mieszkańcy europy bardzo nieprecyzyjny . eleonory , lokalizowanie w wuhanie , potyczki w ksrr , tadeuszowi mazowieckiemu , warunkujące możliwość bieżącego miesiąca ... t. mazowieckiego to skracanie czasu odbywania nauki i postępie i haftów , bf . rudolf ii 3 spowoduje obciążenia zewnętrznego egzaminu adwokackiego z żurawicy . justyna piechocka\n"
     ]
    }
   ],
   "source": [
    "nusg2 = BigramSG(successors2, NonUniformSentenceGenerator)\n",
    "print(nusg2.generate_text(sentences=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "że części z was był w komitecie narodowym w krakowie pod kierunkiem trenera\n",
      "wycofuję się z godnością człowieka\n",
      "1a pkt 12 senat proponuje zmiany dotyczące placówek sg , które braliśmy\n",
      "przeciwdziałanie klęskom żywiołowym i usuwanie drzew lub krzewów z terenu . <EOS>\n",
      "wieku xiii i xiv wieku był właścicielem kilku\n",
      "( gmt ) , architekt wnętrz . <EOS>\n",
      "składowanych na składowiskach ? <EOS>\n",
      ", rozmiaru i charakteru , nie wniosły . <EOS>\n",
      "przez national park . <EOS>\n",
      "przedłużenie do końca v wieku p.n.e. miasto zostało zbudowane z kamienia na planie nieregularnego czworoboku , z wieloletnim doświadczeniem zawodowym i przekwalifikowaniu . <EOS>\n"
     ]
    }
   ],
   "source": [
    "nusg3 = TrigramSG(successors3, NonUniformSentenceGenerator)\n",
    "print(nusg3.generate_text(sentences=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### helper functions for creating bigrams from custom files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', punctuation))\n",
    "\n",
    "\n",
    "def compute_successors(file_name):\n",
    "    successors = {}\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            words = remove_punctuation(line.rstrip('\\n')).split(' ')\n",
    "            for i in range(len(words) - 1):\n",
    "                word1, word2 = list(map(lambda w: w.lower(), words[i:i+2]))\n",
    "                if word1 in successors:\n",
    "                    if word2 in successors[word1]:\n",
    "                        successors[word1][word2] += 1\n",
    "                    else:\n",
    "                        successors[word1][word2] = 1\n",
    "                else:\n",
    "                    successors[word1] = {word2: 1}\n",
    "\n",
    "    scored_successors = {}\n",
    "    for word in successors:\n",
    "        scored_successors[word] = []\n",
    "        for successor in successors[word]:\n",
    "            score = successors[word][successor]\n",
    "            scored_successors[word].append((score, successor))\n",
    "\n",
    "    return scored_successors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_successors = compute_successors('test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sentence scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "\n",
    "def compute_score_of_pair(key, candidate, successors):\n",
    "    if key not in successors:\n",
    "        return 0\n",
    "    if len(successors[key]) == 0:\n",
    "        return 0\n",
    "\n",
    "    for score, successor in successors[key]:\n",
    "        if candidate == successor:\n",
    "            return score\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def compute_sentence_score(sentence, bigrams, trigrams):\n",
    "    score = 0\n",
    "    previous_word = ''\n",
    "    for i in range(len(sentence) - 1):\n",
    "        word1, word2 = sentence[i:i+2]\n",
    "\n",
    "        bigram_key = (word1, )\n",
    "        bigram_score = compute_score_of_pair(\n",
    "            bigram_key, word2, bigrams)\n",
    "\n",
    "        trigram_key = (previous_word, word1)\n",
    "        trigram_score = compute_score_of_pair(\n",
    "            trigram_key, word2, trigrams)\n",
    "\n",
    "        score += max(bigram_score, trigram_score)\n",
    "        previous_word = word1\n",
    "    return score\n",
    "\n",
    "\n",
    "def create_sentences(words, bigrams, trigrams, n=1):\n",
    "    perms = list(permutations(words))\n",
    "    scored = list(\n",
    "        map(lambda p: (p, compute_sentence_score(p, bigrams, trigrams)), perms))\n",
    "    return sorted(scored, key=lambda s: -s[1])[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### default successors from bigram file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'Judyta dała wczoraj Stefanowi czekoladki',\n",
    "    'Babuleńka miała dwa rogate koziołki',\n",
    "    'Wczoraj wieczorem spotkałem pewną piękną kobietę',\n",
    "    'Inauguracja pontyfikatu miała miejsce w trakcie mszy',\n",
    "    'Dodaj kilka zdań do powyższej trójki',\n",
    "    'Nie zakładamy niczego o słowach do uporządkowania'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "(('judyta', 'dała', 'wczoraj', 'stefanowi', 'czekoladki'), 0)\n",
      "(('judyta', 'dała', 'wczoraj', 'czekoladki', 'stefanowi'), 0)\n",
      "(('judyta', 'dała', 'stefanowi', 'wczoraj', 'czekoladki'), 0)\n",
      "(('judyta', 'dała', 'stefanowi', 'czekoladki', 'wczoraj'), 0)\n",
      "(('judyta', 'dała', 'czekoladki', 'wczoraj', 'stefanowi'), 0)\n",
      "--------------------\n",
      "(('babuleńka', 'miała', 'dwa', 'rogate', 'koziołki'), 182)\n",
      "(('babuleńka', 'miała', 'dwa', 'koziołki', 'rogate'), 182)\n",
      "(('babuleńka', 'rogate', 'miała', 'dwa', 'koziołki'), 182)\n",
      "(('babuleńka', 'rogate', 'koziołki', 'miała', 'dwa'), 182)\n",
      "(('babuleńka', 'koziołki', 'miała', 'dwa', 'rogate'), 182)\n",
      "--------------------\n",
      "(('wczoraj', 'wieczorem', 'spotkałem', 'pewną', 'piękną', 'kobietę'), 447)\n",
      "(('wczoraj', 'wieczorem', 'spotkałem', 'piękną', 'kobietę', 'pewną'), 447)\n",
      "(('wczoraj', 'wieczorem', 'pewną', 'spotkałem', 'piękną', 'kobietę'), 447)\n",
      "(('wczoraj', 'wieczorem', 'pewną', 'piękną', 'kobietę', 'spotkałem'), 447)\n",
      "(('wczoraj', 'wieczorem', 'piękną', 'kobietę', 'spotkałem', 'pewną'), 447)\n",
      "--------------------\n",
      "(('inauguracja', 'miała', 'miejsce', 'w', 'trakcie', 'mszy', 'pontyfikatu'), 165359)\n",
      "(('pontyfikatu', 'inauguracja', 'miała', 'miejsce', 'w', 'trakcie', 'mszy'), 165359)\n",
      "(('inauguracja', 'pontyfikatu', 'miała', 'miejsce', 'w', 'trakcie', 'mszy'), 165325)\n",
      "(('pontyfikatu', 'miała', 'miejsce', 'w', 'trakcie', 'mszy', 'inauguracja'), 165325)\n",
      "(('miała', 'miejsce', 'w', 'trakcie', 'mszy', 'inauguracja', 'pontyfikatu'), 165325)\n",
      "--------------------\n",
      "(('dodaj', 'do', 'powyższej', 'kilka', 'zdań', 'trójki'), 2118)\n",
      "(('dodaj', 'do', 'powyższej', 'trójki', 'kilka', 'zdań'), 2118)\n",
      "(('kilka', 'zdań', 'dodaj', 'do', 'powyższej', 'trójki'), 2118)\n",
      "(('kilka', 'zdań', 'trójki', 'dodaj', 'do', 'powyższej'), 2118)\n",
      "(('trójki', 'dodaj', 'do', 'powyższej', 'kilka', 'zdań'), 2118)\n",
      "--------------------\n",
      "(('zakładamy', 'słowach', 'o', 'nie', 'do', 'niczego', 'uporządkowania'), 26692)\n",
      "(('zakładamy', 'uporządkowania', 'słowach', 'o', 'nie', 'do', 'niczego'), 26692)\n",
      "(('słowach', 'o', 'nie', 'do', 'niczego', 'zakładamy', 'uporządkowania'), 26692)\n",
      "(('słowach', 'o', 'nie', 'do', 'niczego', 'uporządkowania', 'zakładamy'), 26692)\n",
      "(('uporządkowania', 'zakładamy', 'słowach', 'o', 'nie', 'do', 'niczego'), 26692)\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    words = sentence.lower().split(' ')\n",
    "    print(20*'-')\n",
    "    for res in create_sentences(words, successors2, successors3, 5):\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
