{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23011601\n"
     ]
    }
   ],
   "source": [
    "def file_len(fname):\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "print(file_len('polish_corpora.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_words_from_file(file_name, lines_to_read):\n",
    "    words = {}\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        for _ in range(lines_to_read):\n",
    "            words_in_line = next(f).rstrip('\\n').split(' ')\n",
    "            for word in words_in_line:\n",
    "                words[word.lower()] = True\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = gather_words_from_file(file_name='polish_corpora.txt', lines_to_read=500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(tokenization_attempt, proper_tokenization):\n",
    "    score = 0\n",
    "    for token in tokenization_attempt:\n",
    "        if token in proper_tokenization:\n",
    "            score +=1\n",
    "    return score / len(proper_tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(['t1', 't2t3', 't3'], ['t1', 't2', 't3', 't3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_match(text):\n",
    "    tokens = []\n",
    "    current_token = ''\n",
    "    for letter in text:\n",
    "        extended_token = current_token + letter\n",
    "        if extended_token in words:\n",
    "            current_token = extended_token\n",
    "        else:\n",
    "            tokens.append(current_token)\n",
    "            current_token = letter\n",
    "    if current_token != '':\n",
    "        tokens.append(current_token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_compare(line):\n",
    "    proper_tokenization = line.lower().split(' ')\n",
    "    processed_line = \"\".join(line.split()).lower()\n",
    "    attempted_tokenization = max_match(processed_line)\n",
    "    score = get_score(attempted_tokenization, proper_tokenization)\n",
    "    print(f'expected: {proper_tokenization}')\n",
    "    print(f'got: {attempted_tokenization}')\n",
    "    print(f'score: {score}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected: ['system', 'euroraty', 'chcesz', 'kupować', 'więcej', 'niż', 'gdzie', 'indziej', '?']\n",
      "got: ['syst', 'eme', 'uro', 'raty', 'ch', 'ces', 'zk', 'upo', 'wać', 'więc', 'ej', 'niż', 'gd', 'zie', 'ind', 'zie', 'j', '?']\n",
      "score: 0.2222222222222222\n",
      "\n",
      "expected: ['parlament', 'zdecydował', 'jednak', 'inaczej', 'i', 'przyjął', 'w', 'ustawie', 'z', 'dnia', '28.06.1996', 'r.', 'jednoinstancyjne', 'postępowanie', 'orzeczniczo-lekarskie', '.']\n",
      "got: ['par', 'lam', 'en', 'tz', 'dec', 'y', 'dowa', 'ł', 'jednak', 'ina', 'czej', 'ip', 'rzy', 'jął', 'wu', 'stawie', 'zd', 'nia', '28.', '06.', '1996r', '.', 'jedno', 'insta', 'nc', 'yj', 'nep', 'ost', 'ę', 'pow', 'anie', 'orz', 'ec', 'zn', 'ic', 'zo', '-', 'lek', 'ars', 'kie', '.']\n",
      "score: 0.1875\n",
      "\n",
      "expected: ['po', 'kampanii', 'wrześniowej', '1.dlek', 'raportowała', '77', 'czołgów', 'l.t.m.35', 'utraconych', '(', 'wraz', 'z', 'wozami', 'dowodzenia', ')', 'i', '52', 'uszkodzone', 'lub', 'zepsute', ',', 'lecz', 'ostatecznie', 'po', 'naprawach', 'straty', 'bezpowrotne', 'ograniczyły', 'się', 'do', '7', 'czołgów', 'i', 'w', 'lutym', '1940', 'roku', 'posiadano', '195', 'czołgów', 'na', 'stanie', '.']\n",
      "got: ['poka', 'mpa', 'nii', 'wrze', 'ś', 'nio', 'wej', '1.', 'dle', 'krap', 'orto', 'wała', '77', 'czo', 'ł', 'gó', 'wl', '.', 't.', 'm.', '35', 'ut', 'rac', 'on', 'ych', '(', 'wraz', 'zwo', 'zam', 'ido', 'wodze', 'nia', ')', 'i5', '2', 'usz', 'kod', 'zo', 'nel', 'ub', 'zep', 'su', 'te', ',', 'lecz', 'ost', 'ate', 'cz', 'nie', 'pona', 'prawa', 'ch', 'straty', 'bez', 'pow', 'rot', 'neo', 'granic', 'zy', 'ły', 'się', 'do', '7c', 'zo', 'ł', 'gó', 'wiw', 'lutym', '1940r', 'okup', 'osi', 'ada', 'no', '195', 'czo', 'ł', 'gó', 'wn', 'asta', 'nie', '.']\n",
      "score: 0.3023255813953488\n",
      "\n",
      "expected: ['w', 'rolach', 'głównych', 'wystąpili', 'jake', 'gyllenhaal', ',', 'forest', 'whitaker', 'oraz', 'rachel', 'mcadams', '.']\n",
      "got: ['wrol', 'ach', 'głów', 'nych', 'wyst', 'ą', 'pili', 'jake', 'gy', 'll', 'en', 'ha', 'al', ',', 'fore', 'stw', 'hita', 'ker', 'oraz', 'rach', 'elm', 'cada', 'ms', '.']\n",
      "score: 0.3076923076923077\n",
      "\n",
      "expected: ['zapieczone', 'z', 'pomidorami', ',', 'bazylią', 'i', 'serem', '...']\n",
      "got: ['zap', 'iec', 'zo', 'nez', 'pomi', 'dora', 'mi', ',', 'bazylią', 'ise', 'rem', '...']\n",
      "score: 0.375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('polish_corpora.txt', encoding='utf8') as f:\n",
    "    for _ in range(5):\n",
    "        line = next(f).rstrip('\\n')\n",
    "        tokenize_and_compare(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The file is kind of scuffed ngl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nie ch ju ż naw et nie będ zie str a żn ic zk ą , a le n ie ch w o góle b ęd zie .\n",
      "Moze nie trzeba by bylo interweniowac a miejsce w zk przydaloby sie komus innemu .\n",
      "A to , czy jakis pies kryl warunkowo czy nie , czy zk jest fajny czy be ...\n"
     ]
    }
   ],
   "source": [
    "with open('polish_corpora.txt', encoding='utf-8') as f:\n",
    "        for _ in range(500000):\n",
    "            line = next(f).rstrip('\\n')\n",
    "            words_in_line = line.split(' ')\n",
    "            if 'zk' in words_in_line:\n",
    "                print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "\n",
    "class SentenceGenerator:\n",
    "    def __init__(self, successors):\n",
    "        self.successors = successors\n",
    "\n",
    "    def random_word(self):\n",
    "        return choice(list(self.successors.keys()))\n",
    "\n",
    "    def random_successor_of(self, word):\n",
    "        successors = self.successors[word]\n",
    "        return choice(successors)[1].split(' ')\n",
    "\n",
    "    def has_successors(self, word):\n",
    "        return word in self.successors and len(self.successors[word]) > 0\n",
    "\n",
    "    def is_end_of_sentence(self, word):\n",
    "        return word in ['<EOS>', '.', '?', '!', '?!', '!?']\n",
    "\n",
    "    def generate_sentence(self):\n",
    "        word = self.random_word()\n",
    "        while not self.has_successors(word):\n",
    "            word = self.random_word()\n",
    "\n",
    "        sentence = [word]\n",
    "        while self.has_successors(word):\n",
    "            successor = self.random_successor_of(word)\n",
    "            word = successor[-1]\n",
    "            sentence += successor\n",
    "\n",
    "        return ' '.join(sentence) + ('.' if not self.is_end_of_sentence(sentence[-1]) else '')\n",
    "    \n",
    "    def generate_text(self, sentences=1):\n",
    "        return '\\n'.join([self.generate_sentence() for _ in range(sentences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_successor(successors, n, word, successor):\n",
    "    successor = (n, successor)\n",
    "    if word in successors:\n",
    "        successors[word].append(successor)\n",
    "    else:\n",
    "        successors[word] = [successor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_successors_from_bigrams(file_name, K=1):\n",
    "    successors = {}\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            n, word1, word2 = line.rstrip('\\n').split(' ')\n",
    "            if (int(n) >= K):\n",
    "                add_successor(successors, int(n), word1, word2)\n",
    "            line = f.readline()\n",
    "    return successors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "successors = gather_successors_from_bigrams('poleval_2grams.txt', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smuty . alfreda dreyfusa , wałbrzych w priorytecie viii 1943 walczył zarówno kierownictwo centralnego : zwykłej - kronika parafii dekanatu jeleśnia , wynegocjowane okresy jej placówki opiekuńczo wychowawcza albo rok 1928 ( płomień sosnowiec to natychmiastowe odwołanie sędziego orzekającego , zegrzu i regenerację tkanek jest uważane jako komercyjny ( fsc . większość zgromadzonych informacji społecznej dotyczącej potrzeby hodowli tych ram prawnych zawierają dzieła jako zasadniczo w północnoeuropejskiej był energicznym i 2318.\\ndrzewcu sztandaru przez polkę i alexa fergusona . prawo nakazywało.\\ncjo nar . łukasza ) ktory jest proces konsolidacji inspekcji farmaceutycznej w rozrywce w indywidualnej umowy dotychczas istniejąca obecnie ruiny dwóch użytkowników do lęgów i myśliwskie i ...... i reprodukcje . 8d.\\nzawitać na śledztwie ? <EOS>\\npiernikami , odbicie również zastosowania regulacji o konserwację obwałowań oraz matki boskiej piekarskiej , wyłączającego obowiązek uzyskać takich sojuszników dla wykonania zadanie zabezpieczenie ze znow to dziewiąte . augusta nie weszły z warrenem.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg = SentenceGenerator(successors)\n",
    "sg.generate_text(sentences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_successors_from_trigrams(file_name, K=1):\n",
    "    successors = {}\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            line = line.rstrip('\\n').split(' ')\n",
    "            if (len(line) != 4): break\n",
    "                \n",
    "            n, word1, word2, word3 = line\n",
    "            if (int(n) >= K):\n",
    "                add_successor(successors, int(n), word1, f'{word2} {word3}')\n",
    "            line = f.readline()\n",
    "    return successors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "successors3 = gather_successors_from_trigrams('poleval_3grams.txt', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'naukowo-techniczną i gospodarczą. inne są nie przysługuje przez to pokolenie. przed dwudziestym rokiem. latem na igelicie. miejsce rozgrywania wyścigu.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg3 = SentenceGenerator(successors3)\n",
    "sg3.generate_text(sentences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NonUniformSentenceGenerator(SentenceGenerator):\n",
    "    def random_successor_of(self, word):\n",
    "        successors = self.successors[word]\n",
    "        total_occurences = sum(list(map(lambda s: s[0], successors)))\n",
    "        probabilites = list(map(lambda s: s[0] / total_occurences, successors))\n",
    "        successors = list(map(lambda s: s[1], successors))\n",
    "\n",
    "        return [np.random.choice(successors, 1, probabilites)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boecjusz , wchłonięta przez rzeźbiarzy i skorzystają na żyłę , powiadamia się zatnie.\n",
      "sese seko . kapitał polski klub jednak zasady pluralizmu związkowego , odcinkiem specjalnym koncercie z działów kadr jest upoważnienie nie żarty z dachem trójspadowym dachem - warunkiem zatwierdzenia tej dacie premiery to otrzymaliśmy dopiero druga kwestia najbliższych wyborów prezydenckich do fizjologicznego porodu rodzinnego wraz . bonifratrów . urz . władysław kalkus.\n",
      "ge- netics.\n",
      "ustawiczne , 586 p.n.e. prawdopodobnie przez przewodniczących właściwych parametrach zbliżonych rozmiarach niż pokazują przynajmniej kilkuset cywilów na dyrektorskim stanowisku pracownika fizycznego o niecałe 900 mm to udostępnianie zawartości zanieczyszczeń odprowadzanych w oficynie , zbycie nastąpiło zaniechanie przy oglądaniu telewizji publicznych wynika ich wychowanie muzyczne mp3 ... macie czas co były ułatwione jest rzędem temu dostał posadę szefa łączności 1 wskazuje do niedotlenienia . 52 cm kolor można obecnie sprawozdanie końcowe rozliczenie na malowniczej , wyeliminują zaistniałe na akumulator li-ion , pionowa linia frontu podolskiego na talię kart naszej bibliotece jest wydane oraz pismo , sektory : podstawa wykonana nowa idea stworzenia sobie zdania jest rekonstrukcja . 67 ww. rodzajach kształcenia wyższego korpusu północ-wschód , wyspecjalizowana w kryminalną i utroque iure ) 1000 km biegnie następnie przesyła ministrowi ustalenie opłaty byłyby tutaj wymienił też nawiązuje współpracę . 47 wniosków podejmowana decyzja ze zużytego na nastrój zbliżających się analogiczny wniosek odrzucić ofertę biura wojskowego sądu rodzinnego oznacza dyskryminację innych szkód komunikacyjnych łączących je mogą sobie operację zmiany organizacyjno-dyslokacyjne.\n",
      "patrolować ulice na wygenerowanie prognozy dotyczące kampanii 2006 przewodniczył uroczystej mszy odprawianej przez podgrzewanie wody niegazowanej wody mineralne ( aircraft . dwa węzły autostradowe , forrest gump , talk i śmiałości , legitymować osoby jest rekordzistką kraju inwestycje jak wydać decyzji zgromadzenia obligatariuszy , hutnictwie żelaza o raporcie komisji regulaminowej zgromadzenia przed odbiciem w 1571 ) bądź religijną . no sory , dziegieć , femme . zdzisława jankowskiego w kustodii ziemi także prowadzili przez wiarę czy białe prążki , czystych źródeł miało zapewniać będzie te znają prawdę tylko banki odmawiają partycypowania przez instalacje technologiczne ) zostaną wypłacone świadczenie rodzinne finansowane do ubikacji i giuseppe , usiadłam na płody i nagród to skupiska polonii i żądaniami . dwt . b2 - utrudnia postępowanie scaleniowe . marcina króla michała kleibera . urz..\n"
     ]
    }
   ],
   "source": [
    "nusg2 = NonUniformSentenceGenerator(successors)\n",
    "print(nusg2.generate_text(sentences=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indianami północnego zachodu.\n",
      "czwarta w tej.\n",
      "oceniana była jako.\n",
      "wielu wypadkach gminy.\n",
      "sieci odpowiadający zapotrzebowaniu.\n"
     ]
    }
   ],
   "source": [
    "nusg3 = NonUniformSentenceGenerator(successors3)\n",
    "print(nusg3.generate_text(sentences=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
