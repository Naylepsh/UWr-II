{
 "cells": [
  {
   "source": [
    "## Ex 3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logger import FileProcessLogger, file_line_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_and_tags():\n",
    "    tag_of_word = {}\n",
    "    words_with_tag = {}\n",
    "    filename = './dane/supertags.txt'\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        logger = FileProcessLogger(filename)\n",
    "        for line in file:\n",
    "            logger.update()\n",
    "            word, tag = line.lower().rstrip('\\n').split()\n",
    "            tag_of_word[word] = tag\n",
    "            if tag in words_with_tag:\n",
    "                words_with_tag[tag].append(word)\n",
    "            else:\n",
    "                words_with_tag[tag] = [word]\n",
    "    return tag_of_word, words_with_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processed 10% of the file contents...\n",
      "Processed 20% of the file contents...\n",
      "Processed 30% of the file contents...\n",
      "Processed 40% of the file contents...\n",
      "Processed 50% of the file contents...\n",
      "Processed 60% of the file contents...\n",
      "Processed 70% of the file contents...\n",
      "Processed 80% of the file contents...\n",
      "Processed 90% of the file contents...\n",
      "Processed 100% of the file contents...\n"
     ]
    }
   ],
   "source": [
    "tag_of_word, words_with_tag = get_words_and_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram():\n",
    "    filename = './dane/poleval_2grams.txt'\n",
    "    bigram = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        logger = FileProcessLogger(filename)\n",
    "        for line in file:\n",
    "            logger.update()\n",
    "            n, word1, word2 = line.lower().split()\n",
    "            n = int(n)\n",
    "            if n < 10: \n",
    "                continue\n",
    "            if word1 in bigram:\n",
    "                bigram[word1].append((word2, n))\n",
    "            else:\n",
    "                bigram[word1] = [(word2, n)]\n",
    "    return bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processed 10% of the file contents...\n",
      "Processed 20% of the file contents...\n",
      "Processed 30% of the file contents...\n",
      "Processed 40% of the file contents...\n",
      "Processed 50% of the file contents...\n",
      "Processed 60% of the file contents...\n",
      "Processed 70% of the file contents...\n",
      "Processed 80% of the file contents...\n",
      "Processed 90% of the file contents...\n",
      "Processed 100% of the file contents...\n"
     ]
    }
   ],
   "source": [
    "bigram = get_bigram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def to_unigram(bigram):\n",
    "    unigram = {}\n",
    "    unigram = defaultdict(lambda: 0, unigram)\n",
    "    for word1 in bigram:\n",
    "        for word2, n in bigram[word1]:\n",
    "            unigram[word1] += n\n",
    "            unigram[word2] += n\n",
    "    return unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = to_unigram(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_unigram_probability(word):\n",
    "    if word in unigram:\n",
    "        return unigram[word]\n",
    "    return 0.0001\n",
    "\n",
    "\n",
    "def choose_from_unigram(words):\n",
    "    probs = np.array([get_unigram_probability(x) for x in words])\n",
    "    probs = probs / np.sum(probs)\n",
    "    return str(np.random.choice(words, 1, p=probs)[0])\n",
    "\n",
    "\n",
    "def get_tag(word):\n",
    "    if word in tag_of_word:\n",
    "        return tag_of_word[word]\n",
    "    return tag_of_word[('^' + word)[-3:]]\n",
    "\n",
    "\n",
    "def random_similar_sentence(original):\n",
    "    words = original.lower().split()\n",
    "    tags = list(map(get_tag, words))\n",
    "    alternative_words = list(map(lambda tag: words_with_tag[tag], tags))\n",
    "    chosen_words = list(map(choose_from_unigram, alternative_words))\n",
    "    return ' '.join(chosen_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Mały Piotruś spotkał w niewielkiej restauracyjce wczoraj poznaną koleżankę\",\n",
    "    \"Litwo Ojczyzno moja Ty jesteś jak zdrowie\",\n",
    "    \"Jeden z pojmanych najemników probował odebrać to ostrze\",\n",
    "    \"Jak może być inaczej dopóki gildia znajduje się poza imperialną kontrolą\",\n",
    "    \"Jak sobie życzysz\",\n",
    "    \"Książę popatrzył spode łba i zajął się sterami\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "początkowy szymon podjął po niedalekiej zmianie niekiedy daną dolinę\nsargo grado która ty żyjesz jak wykonywanie\njeden z zlokalizowanych rolników pkt nacisnąć to potomstwo\njak może być ponadto póki mowa porusza się poza społeczną wielkością\njak sobie chcesz\nksiążę pojawił spode ratusza i opublikował się włoskami\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(random_similar_sentence(sentence))"
   ]
  },
  {
   "source": [
    "## Ex 4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram_probability(word, successor):\n",
    "    if successor in bigram[word]:\n",
    "        return bigram[word][successor]\n",
    "    return 0.0001\n",
    "\n",
    "\n",
    "def choose_from_bigram(word, successors):\n",
    "    probs = np.array([get_bigram_probability(word, successor) for successor in successors])\n",
    "    probs = probs / np.sum(probs)\n",
    "    return str(np.random.choice(successors, 1, p=probs)[0])\n",
    "\n",
    "\n",
    "def random_similar_sentence_v2(original):\n",
    "    words = original.lower().split()\n",
    "    tags = list(map(get_tag, words))\n",
    "    alternative_words = list(map(lambda tag: words_with_tag[tag], tags))\n",
    "    words_in_bigram = { word for word in bigram }\n",
    "    \n",
    "    best = ([], len(words))\n",
    "    for _ in range(100):\n",
    "        fails = 0\n",
    "        known_alternatives = set(alternative_words[0])\n",
    "        available_words = known_alternatives.intersection(words_in_bigram)\n",
    "        word = choose_from_unigram(list(available_words))\n",
    "        sentence = [word]\n",
    "        for i in range(1, len(words)):\n",
    "            known_alternatives = set(alternative_words[i])\n",
    "            allowed_words = { successor for successor in bigram[word] }\n",
    "            available_words = known_alternatives.intersection(allowed_words)\n",
    "\n",
    "            if len(available_words) > 0:\n",
    "                word = choose_from_bigram(word, list(available_words))\n",
    "                sentence.append(word)\n",
    "            else: \n",
    "                fails += 1      \n",
    "                sentence.append('|')                \n",
    "                allowed_words = { word for word in bigram }\n",
    "                available_words = known_alternatives.intersection(allowed_words)\n",
    "                word = choose_from_unigram(list(available_words))\n",
    "                sentence.append(word)\n",
    "        if fails < best[1]:\n",
    "            best = (sentence, fails)\n",
    "        \n",
    "    return ' '.join(best[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ekonomiczny | farmer | zagrał | w | niedalekiej | stronie | tuż | wyrażoną | pieczę\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c497ee050d97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_similar_sentence_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-8a06f675b06b>\u001b[0m in \u001b[0;36mrandom_similar_sentence_v2\u001b[1;34m(original)\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[0mallowed_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbigram\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[0mavailable_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknown_alternatives\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallowed_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                 \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchoose_from_unigram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavailable_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m                 \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfails\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-ddb5f5ad583a>\u001b[0m in \u001b[0;36mchoose_from_unigram\u001b[1;34m(words)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mchoose_from_unigram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mget_unigram_probability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprobs\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-ddb5f5ad583a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mchoose_from_unigram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mget_unigram_probability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprobs\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(random_similar_sentence_v2(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mazowiecki kombinator wyprzedził pomiędzy niesamodzielnej eurolidze kameralnie ukształtowaną zagadkę'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'Mały Piotruś spotkał w niewielkiej restauracyjce wczoraj poznaną koleżankę'\n",
    "random_similar_sentence_v2(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wojskowy | budnik | ukończył | w | niepodległej | polsce | poniżej | używaną | stronę\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'|'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-4ec56af71db0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mwr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtag_of_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtag_of_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mto\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '|'"
     ]
    }
   ],
   "source": [
    "for _ in range(30):\n",
    "    res = random_similar_sentence_v2(s)\n",
    "    print(res)\n",
    "    original_words = s.lower().split()\n",
    "    res_words = res.split()\n",
    "    for i in range(len(original_words)):\n",
    "        wo = original_words[i]\n",
    "        if wo not in tag_of_word:\n",
    "            wo = wo[-3:]\n",
    "        wr = res_words[i]\n",
    "        if wr not in tag_of_word:\n",
    "            wr = wr[-3:]\n",
    "        to = tag_of_word[wo]\n",
    "        tr = tag_of_word[wr]\n",
    "        if to != tr:\n",
    "            print(original_words[i], to, res_words[i], tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "widoczny | pan | posiadł | w | niezwłocznej | formie | bardzo | uzgodnioną | olszynkę\n",
      "failed for widoczny |\n",
      "no alt for |\n",
      "failed for pan |\n",
      "no alt for |\n",
      "failed for posiadł |\n",
      "no alt for |\n",
      "failed for w |\n",
      "no alt for |\n",
      "failed for niezwłocznej |\n",
      "no alt for |\n",
      "failed for formie |\n",
      "no alt for |\n",
      "failed for bardzo |\n",
      "no alt for |\n",
      "failed for uzgodnioną |\n",
      "no alt for |\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1):\n",
    "    res = random_similar_sentence_v2(s)\n",
    "    print(res)\n",
    "    res_words = res.split()\n",
    "    for i in range(len(res_words)-1):\n",
    "        w1, w2 = res_words[i:i+2]\n",
    "        if w1 in bigram:\n",
    "            if w2 not in bigram[w1]:\n",
    "                print('failed for', w1, w2)\n",
    "        if w1 not in bigram:\n",
    "            alt = ('^'+w1)[-3:]\n",
    "            if alt in bigram:\n",
    "                if w2 not in bigram[alt][w2]:\n",
    "                    print('failed for', alt, w2)\n",
    "            else:\n",
    "                print('no alt for', w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}