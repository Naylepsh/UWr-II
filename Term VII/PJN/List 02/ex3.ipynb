{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logger import FileProcessLogger, file_line_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_and_tags():\n",
    "    tag_of_word = {}\n",
    "    words_with_tag = {}\n",
    "    filename = './dane/supertags.txt'\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        logger = FileProcessLogger(filename)\n",
    "        for line in file:\n",
    "            logger.update()\n",
    "            word, tag = line.lower().split()\n",
    "            tag_of_word[word] = tag\n",
    "            if tag in words_with_tag:\n",
    "                words_with_tag[tag].append(word)\n",
    "            else:\n",
    "                words_with_tag[tag] = [word]\n",
    "    return tag_of_word, words_with_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10% of the file contents...\n",
      "Processed 20% of the file contents...\n",
      "Processed 30% of the file contents...\n",
      "Processed 40% of the file contents...\n",
      "Processed 50% of the file contents...\n",
      "Processed 60% of the file contents...\n",
      "Processed 70% of the file contents...\n",
      "Processed 80% of the file contents...\n",
      "Processed 90% of the file contents...\n",
      "Processed 100% of the file contents...\n"
     ]
    }
   ],
   "source": [
    "tag_of_word, words_with_tag = get_words_and_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram():\n",
    "    filename = './dane/poleval_2grams.txt'\n",
    "    bigram = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        logger = FileProcessLogger(filename)\n",
    "        for line in file:\n",
    "            logger.update()\n",
    "            n, word1, word2 = line.lower().split()\n",
    "            n = int(n)\n",
    "            if n < 10: \n",
    "                continue\n",
    "            if word1 in bigram:\n",
    "                bigram[word1].append((word2, n))\n",
    "            else:\n",
    "                bigram[word1] = [(word2, n)]\n",
    "    return bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10% of the file contents...\n",
      "Processed 20% of the file contents...\n",
      "Processed 30% of the file contents...\n",
      "Processed 40% of the file contents...\n",
      "Processed 50% of the file contents...\n",
      "Processed 60% of the file contents...\n",
      "Processed 70% of the file contents...\n",
      "Processed 80% of the file contents...\n",
      "Processed 90% of the file contents...\n",
      "Processed 100% of the file contents...\n"
     ]
    }
   ],
   "source": [
    "bigram = get_bigram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def to_unigram(bigram):\n",
    "    unigram = {}\n",
    "    unigram = defaultdict(lambda: 0, unigram)\n",
    "    for word1 in bigram:\n",
    "        for word2, n in bigram[word1]:\n",
    "            unigram[word1] += n\n",
    "            unigram[word2] += n\n",
    "    return unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = to_unigram(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_unigram_probability(word):\n",
    "    if word in unigram:\n",
    "        return unigram[word]\n",
    "    return 0.0001\n",
    "\n",
    "\n",
    "def choose_from_unigram(words):\n",
    "    probs = np.array([get_unigram_probability(x) for x in words])\n",
    "    probs = probs / np.sum(probs)\n",
    "    return str(np.random.choice(words, 1, p=probs)[0])\n",
    "\n",
    "\n",
    "def get_tag(word):\n",
    "    if word in tag_of_word:\n",
    "        return tag_of_word[word]\n",
    "    return tag_of_word[('^' + word)[-3:]]\n",
    "\n",
    "\n",
    "def random_similar_sentence(original):\n",
    "    words = original.lower().split()\n",
    "    tags = list(map(get_tag, words))\n",
    "    alternative_words = list(map(lambda tag: words_with_tag[tag], tags))\n",
    "    chosen_words = list(map(choose_from_unigram, alternative_words))\n",
    "    return ' '.join(chosen_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Mały Piotruś spotkał w niewielkiej restauracyjce wczoraj poznaną koleżankę\",\n",
    "    \"Litwo Ojczyzno moja Ty jesteś jak zdrowie\",\n",
    "    \"Jeden z pojmanych najemników probował odebrać to ostrze\",\n",
    "    \"Jak może być inaczej dopóki gildia znajduje się poza imperialną kontrolą\",\n",
    "    \"Jak sobie życzysz\",\n",
    "    \"Książę popatrzył spode łba i zajął się sterami\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "północny dyrektor uchwalił w niezbędnej formie zgodnie produkowaną stację\n",
      "izbo etno która ty jesteś jak przyznanie\n",
      "jeden z przeznaczonych posłów rząd podnieść to pokrycie\n",
      "jak może być bardzo czyli oferta wchodzi się poza jagiellońskim deską\n",
      "jak sobie potrzebujesz\n",
      "książę nabył spode względu i ruszył się składnikami\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(random_similar_sentence(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram_probability(word, successor):\n",
    "    if successor in bigram[word]:\n",
    "        return bigram[word][successor]\n",
    "    return 0.0001\n",
    "\n",
    "\n",
    "def choose_from_bigram(word, successors):\n",
    "    probs = np.array([get_bigram_probability(word, successor) for successor in successors])\n",
    "    probs = probs / np.sum(probs)\n",
    "    return str(np.random.choice(successors, 1, p=probs)[0])\n",
    "\n",
    "\n",
    "def random_similar_sentence_v2(original):\n",
    "    words = original.lower().split()\n",
    "    tags = list(map(get_tag, words))\n",
    "    alternative_words = list(map(lambda tag: words_with_tag[tag], tags))\n",
    "    words_in_bigram = { word for word in bigram }\n",
    "    \n",
    "    i = 0\n",
    "    sentence = []   \n",
    "    while i < len(words):\n",
    "        known_alternatives = set(alternative_words[i])\n",
    "        available_words = known_alternatives.intersection(words_in_bigram)\n",
    "        word = choose_from_unigram(list(available_words))\n",
    "        sentence.append(word)\n",
    "        i += 1\n",
    "        \n",
    "        while word in bigram and i < len(words):\n",
    "            known_alternatives = set(alternative_words[i])\n",
    "            allowed_words = { successor for successor in bigram[word] }\n",
    "            available_words = known_alternatives.intersection(allowed_words)\n",
    "            if len(available_words) == 0:\n",
    "                break\n",
    "\n",
    "            for x in available_words:\n",
    "                assert x in bigram[word]\n",
    "            \n",
    "            res = choose_from_bigram(word, list(available_words))\n",
    "            assert res in bigram[word]\n",
    "            word = res\n",
    "            sentence.append(word)\n",
    "            i += 1\n",
    "        sentence.append('|')\n",
    "    return ' '.join(sentence[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hodowlany | prezydent | założył | w | nieuczciwej | zmianie | stosownie | zawartą | procedurę\n",
      "izbo | bojko | która | ty | jesteś | jak | tworzenie\n",
      "jeden | ze | zgłaszanych | mężczyzn | zakres | wziąć | to | miejsce\n",
      "jak | może | być | obecnie | oraz | fabryka | pozostawia | się | poza | całą | intencją\n",
      "jak | sobie | możesz\n",
      "książę | przybył | spode | kontraktu | i | ukazał | się | kosztami\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(random_similar_sentence_v2(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mazowiecki kombinator wyprzedził pomiędzy niesamodzielnej eurolidze kameralnie ukształtowaną zagadkę'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'Mały Piotruś spotkał w niewielkiej restauracyjce wczoraj poznaną koleżankę'\n",
    "random_similar_sentence_v2(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wojskowy | budnik | ukończył | w | niepodległej | polsce | poniżej | używaną | stronę\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'|'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-4ec56af71db0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mwr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtag_of_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtag_of_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mto\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '|'"
     ]
    }
   ],
   "source": [
    "for _ in range(30):\n",
    "    res = random_similar_sentence_v2(s)\n",
    "    print(res)\n",
    "    original_words = s.lower().split()\n",
    "    res_words = res.split()\n",
    "    for i in range(len(original_words)):\n",
    "        wo = original_words[i]\n",
    "        if wo not in tag_of_word:\n",
    "            wo = wo[-3:]\n",
    "        wr = res_words[i]\n",
    "        if wr not in tag_of_word:\n",
    "            wr = wr[-3:]\n",
    "        to = tag_of_word[wo]\n",
    "        tr = tag_of_word[wr]\n",
    "        if to != tr:\n",
    "            print(original_words[i], to, res_words[i], tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "widoczny | pan | posiadł | w | niezwłocznej | formie | bardzo | uzgodnioną | olszynkę\n",
      "failed for widoczny |\n",
      "no alt for |\n",
      "failed for pan |\n",
      "no alt for |\n",
      "failed for posiadł |\n",
      "no alt for |\n",
      "failed for w |\n",
      "no alt for |\n",
      "failed for niezwłocznej |\n",
      "no alt for |\n",
      "failed for formie |\n",
      "no alt for |\n",
      "failed for bardzo |\n",
      "no alt for |\n",
      "failed for uzgodnioną |\n",
      "no alt for |\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1):\n",
    "    res = random_similar_sentence_v2(s)\n",
    "    print(res)\n",
    "    res_words = res.split()\n",
    "    for i in range(len(res_words)-1):\n",
    "        w1, w2 = res_words[i:i+2]\n",
    "        if w1 in bigram:\n",
    "            if w2 not in bigram[w1]:\n",
    "                print('failed for', w1, w2)\n",
    "        if w1 not in bigram:\n",
    "            alt = ('^'+w1)[-3:]\n",
    "            if alt in bigram:\n",
    "                if w2 not in bigram[alt][w2]:\n",
    "                    print('failed for', alt, w2)\n",
    "            else:\n",
    "                print('no alt for', w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
